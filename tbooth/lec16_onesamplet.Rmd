---
title: "Lecture 16: One-Sample t-test"
subtitle: Data Analysis for Psychology in R 1
author: Tom Booth
---
```{r premable, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(kableExtra)
library(patchwork)
library(moderndive)
```

## Today
- Introduce the three types of $t$-test:
- Discuss in detail one-sample $t$-tests
	- When to use
	- Tested hypotheses
	- Calculation
	- Doing in R
	- Write up
	
## Learning objectives
- Understand when to use a one sample $t$-test
- Understand the null hypothesis for a one sample $t$-test
- Understand how to calculate the test statistic
- Know how to conduct the test in R

## Purpose
- $t$-tests (generally) concern testing the difference between two means.
  - One-sample $t$-tests compare the mean in a sample to a known mean .
  - Independent $t$-tests compare the means of two independent samples.
  - Paired sample $t$-tests compare the mean from a single sample at two points in time (repeated measurements)

## Data Requirements: One-sample t-test
- A continuous variable.
  - Remember we are calculating means.
- A known mean that we wish to compare our sample to.
- A sample of data from which we calculate the sample mean.

## Hypotheses
- We are comparing a single sample mean $\mu_1$ to a known mean $\mu$ 

$$
H_0: \mu = \mu_1
$$

- Note this is identical to saying:


$$
H_0: \mu - \mu_1 = 0
$$

## Alternative Hypotheses
- Two-tailed:

$$
\begin{matrix}
H_0: \mu = \mu_1 \\
H_1: \mu \neq \mu_1
\end{matrix}
$$

- One-tailed:


$$
\begin{matrix}
H_0: \mu = \mu_1 \\
H_1: \mu < \mu_1 \\
H_1: \mu > \mu_1
\end{matrix}
$$

## Are these means different?

```{r, echo=FALSE}
ggplot(NULL, aes(x=125:200)) +
  geom_vline(xintercept = 150) +
  geom_vline(xintercept = 170, col="red") +
  xlim(125, 200) +
  xlab("\n Height")
```


## What about these?

```{r, echo=FALSE}
ggplot(NULL, aes(x=125:200)) +
  geom_vline(xintercept = 140) +
  geom_vline(xintercept = 190, col="red") +
  xlim(125, 200) +
  xlab("\n Height")
```

## Differences in means
- Why can we not tell whether they are different or not?
- What else might we want to know in order to know whether not the group means could be thought of as coming from the same distribution?


## All the information

```{r, echo=FALSE}
ggplot(NULL, aes(x = c(125:200))) +
  stat_function(fun=dnorm,
                geom = "line",
                args = list(mean=150, sd=10)) +
  stat_function(fun = dnorm,
                geom = "line",
                col = "red",
                args = list(mean=170, sd=10)) +
  geom_vline(xintercept = 150) +
  geom_vline(xintercept = 170, col="red") +
  xlab("\n Height") +
  ylab("") +
  ggtitle("Comparing means")

```

## All the information

```{r, echo=FALSE}
ggplot(NULL, aes(x = c(125:200))) +
  stat_function(fun=dnorm,
                geom = "line",
                args = list(mean=150, sd=2)) +
  stat_function(fun = dnorm,
                geom = "line",
                col = "red",
                args = list(mean=170, sd=2)) +
  geom_vline(xintercept = 150) +
  geom_vline(xintercept = 170, col="red") +
  xlab("\n Height") +
  ylab("") +
  ggtitle("Comparing means")

```

## t-statistic
- Recall when talking about hypothesis testing:
  - We calculate a test statistic that represents our question.
  - We compare our sample value to the sampling distribution under the null
- Here the test statistic is a $t$-statistic.

  
## t-statistic

$$
t = \frac{\bar{x} - \mu}{\frac{s}{\sqrt{N}}}
$$

- where
  - $s$ = sample estimated standard deviation of $x$
  - $N$ = sample size
- The numerator = a difference is means
- The denominator = a estimate of variability
- $t$ = a standardized difference in means.

## And breath
- **Example:** Suppose I want to know whether the retirement age of Professors in my department is the same as the national average.
- The national average age of retirement for Prof's 65.
- So I look at the age of the last five Prof's that have retired at Edinburgh and compare against this value.

## Data

```{r, echo=FALSE}
df <- tibble(
  ID = c(paste("Prof", 1:5, sep ="")),
  Age = c(40, 70, 85, 80, 75)
)
df

```


## Hypotheses
- Let's say I am new to the department and a priori have no idea of the ages they retired.
- So I specify a two-tailed hypothesis with $\alpha$ = 0.05.
- So I am simply asking, does my mean differ from the known mean.

## Calculation

$$
t = \frac{\bar{x} - \mu}{\frac{s}{\sqrt{N}}}
$$

- Steps to calculate $t$:
  - Calculate the sample mean ($\bar{x}$).
  - Calculate the sample standard deviation ($s$).
  - Check I know my N.
  - Calculate the standard error of the mean ($\frac{s}{\sqrt{N}}$).
  - Use all this to calculate t.

## Calculation
```{r}
df %>%
  summarise(
    PopMean = 65,
    Mean = mean(Age),
    SD = sd(Age),
    N = n()
  ) %>%
  mutate(
    SE = SD/sqrt(N)
  )
```

## Calculation

```{r, echo=FALSE}
df %>%
  summarise(
    PopMean = 65,
    Mean = mean(Age),
    SD = sd(Age),
    N = n()
  ) %>%
  mutate(
    SE = SD/sqrt(N)
  )
```


$$
t = \frac{\bar{x} - \mu}{\frac{s}{\sqrt{N}}} = \frac{70-65}{\frac{17.7}{\sqrt{5}}} = \frac{5}{7.91} = 0.63
$$

## Is our test significant?
- The sampling distribution for $t$-statistics is a $t$-distribution.
- The t-distribution is a continuous probability distribution very similar to the normal distribution.
  - Key parameter = degrees of freedom (df)
	- df are a function of N.
	- As N increases (and thus as df increases), the t-distribution approaches a normal distribution.
- For a one sample $t$-test, we compare our test statistic to a $t$-distribution with N-1 df.

## Is our test significant?
- So we have all the pieces we need:
  - Degrees of freedom = N-1 = 5-1 = 4
  - We have our t-statistic (0.63)
  - Hypothesis to test (two-tailed)
  - $\alpha$ level (0.05).
- So now all we need is the critical value from the associated $t$-distribution in order to make our decision.

## Is our test significant?

```{r}
tibble(
  LowerCrit = round(qt(0.025, 4),2),
  UpperCrit = round(qt(0.975, 4),2),
)
```

## Is our test significant?

```{r, echo=FALSE}
ggplot(NULL, aes(x = c(-6,6))) +
  stat_function(fun=dt,
                geom = "line",
                args = list(df=4)) +
  stat_function(fun = dt, 
                geom = "area",
                xlim = c(2.776445, 6),
                alpha=.25,
                fill = "blue",
                args = list(df=4)) +
    stat_function(fun = dt, 
                geom = "area",
                xlim = c(-2.776445, -6),
                alpha=.25,
                fill = "blue",
                args = list(df=4)) +
  geom_vline(xintercept = 0.63, col="red") +
  xlab("\n t") +
  ylab("") +
  ggtitle("t-distribution (df=4); t-statistic (0.63; red line)")
```

```{r, echo=FALSE}
tibble(
  LowerCrit = round(qt(0.025, 4),2),
  UpperCrit = round(qt(0.975, 4),2),
)
```

## Is our test significant?
- So our critical value is 2.78
  - Our t-statistic is less than this, 0.63.
  - So we fail to reject the null hypothesis.
- t(4)=0.63, p > .05, two-tailed.


## Exact p-values

```{r}
tibble(
  LowerCrit = round(qt(0.025, 4),2),
  UpperCrit = round(qt(0.975, 4),2),
  Exactp = round(2*(1-pt(0.63, 4)),2)
)
```


## Exact p-values

```{r, echo=FALSE}
ggplot(NULL, aes(x = c(-6,6))) +
  stat_function(fun=dt,
                geom = "line",
                args = list(df=4)) +
  stat_function(fun = dt, 
                geom = "area",
                xlim = c(0.63, 6),
                alpha=.25,
                fill = "red",
                args = list(df=4)) +
    stat_function(fun = dt, 
                geom = "area",
                xlim = c(-0.63, -6),
                alpha=.25,
                fill = "red",
                args = list(df=4)) +
  geom_vline(xintercept = 0.63, col="red") +
  xlab("\n t") +
  ylab("") +
  ggtitle("t-distribution (df=4); t-statistic (0.63; red line)")
```



```{r, echo=FALSE}
tibble(
  LowerCrit = round(qt(0.025, 4),2),
  UpperCrit = round(qt(0.975, 4),2),
  Exactp = round(2*(1-pt(0.63, 4)),2)
)
```

## In R

```{r}
t.test(df$Age, mu=65, alternative="two.sided")
```

## Write up
A one-sample t-test was conducted in order to determine if a statistically significant ($\alpha$=.05) mean difference existed between the average retirement age of Professors, and the age at retirement of a sample of 5 psychology Professors. The sample scored higher (Mean=`r mean(df$Age)`, SD=`r round(sd(df$Age),2)`) than the population (Mean = 65), however the difference was not statistically significant (t(4)=0.63, p > .05, two-tailed). 

## Assumptions
- As noted above, we have some requirements of the data:
  - DV is continuous.
- But we also have some additional model assumptions for the test to be valid.
  - The data are normally distributed.
  - The data are an independent random sample.
- (2) we can not directly test.
- (1) we can test using a QQplot, histograms and a Shapiro-Wilks Test.

## Tasks for this week...
1. Catch up any tasks from previous weeks. 
2. Quiz 16: Probability distributions and hypothesis testing
    - Today at 17:00.
    - Close Monday 3rd at 17:00
    